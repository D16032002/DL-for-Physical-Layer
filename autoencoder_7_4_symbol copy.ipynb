{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, GaussianNoise\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 16 k: 4\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "M = 16 \n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "print ('M:',M,'k:',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 10000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "12 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "12 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "R = 4/7\n",
    "n_channel = 7\n",
    "print (int(k/R))\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = BatchNormalization()(encoded1)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "#sgd = SGD(lr=0.001)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7)                28        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 7)                0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                128       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 819\n",
      "Trainable params: 805\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_val = 1500\n",
    "val_label = np.random.randint(M,size=N_val)\n",
    "val_data = []\n",
    "for i in val_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    val_data.append(temp)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 3s 26ms/step - loss: 2.6820 - val_loss: 2.6961\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 2.1882 - val_loss: 2.5580\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1.7674 - val_loss: 2.3583\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 1.3940 - val_loss: 2.0911\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 1.0597 - val_loss: 1.7662\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7861 - val_loss: 1.4141\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5682 - val_loss: 1.0537\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3981 - val_loss: 0.7281\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2807 - val_loss: 0.4649\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2001 - val_loss: 0.2847\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1476 - val_loss: 0.1723\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1100 - val_loss: 0.1071\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0869 - val_loss: 0.0697\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0702 - val_loss: 0.0477\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0574 - val_loss: 0.0342\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0469 - val_loss: 0.0258\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0415 - val_loss: 0.0203\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.0163\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.0134\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0114\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0237 - val_loss: 0.0098\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0085\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0075\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0066\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0059\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0053\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0039\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0036\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0033\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0030\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.0028\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0022\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 9.5672e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 8.9776e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 8.6004e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 8.1469e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 7.7274e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 7.3576e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 6.9951e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 6.5819e-04\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 6.2418e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 5.9806e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 5.7033e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 5.4086e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 5.1581e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 4.9652e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 4.8307e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 4.6105e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 4.3947e-04\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.1999e-04\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 4.0330e-04\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 3.8369e-04\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 3.6728e-04\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 3.5208e-04\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 3.3806e-04\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 3.2523e-04\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 3.1215e-04\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0012 - val_loss: 2.9809e-04\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 2.8762e-04\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 2.7668e-04\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 2.6567e-04\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 2.5717e-04\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.8297e-04 - val_loss: 2.4555e-04\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 9.5064e-04 - val_loss: 2.3795e-04\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.6513e-04 - val_loss: 2.2933e-04\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.1463e-04 - val_loss: 2.1858e-04\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8.8804e-04 - val_loss: 2.1174e-04\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 9.0058e-04 - val_loss: 2.0461e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 8.1697e-04 - val_loss: 1.9672e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7.5258e-04 - val_loss: 1.9012e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 8.1619e-04 - val_loss: 1.8409e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7.6484e-04 - val_loss: 1.7896e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7.5149e-04 - val_loss: 1.7154e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 6.9840e-04 - val_loss: 1.6438e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 7.0654e-04 - val_loss: 1.5845e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 7.1726e-04 - val_loss: 1.5354e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 6.5349e-04 - val_loss: 1.4860e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 6.3981e-04 - val_loss: 1.4335e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.9603e-04 - val_loss: 1.3952e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.9954e-04 - val_loss: 1.3425e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 5.7732e-04 - val_loss: 1.3046e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 5.6835e-04 - val_loss: 1.2617e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.9070e-04 - val_loss: 1.2078e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 5.6502e-04 - val_loss: 1.1655e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6e009bc70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data, data,\n",
    "                epochs=100,\n",
    "                batch_size=300,\n",
    "                validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 45000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 11\n"
     ]
    }
   ],
   "source": [
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1a6e009a020>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: -4 BER: 0.21624444444444443\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -3.5 BER: 0.1761111111111111\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: -3.0 BER: 0.14893333333333333\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -2.5 BER: 0.11597777777777778\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -2.0 BER: 0.09071111111111112\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -1.5 BER: 0.06655555555555556\n",
      "1407/1407 [==============================] - 9s 6ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -1.0 BER: 0.04953333333333333\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -0.5 BER: 0.0344\n",
      "1407/1407 [==============================] - 7s 5ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 0.0 BER: 0.0226\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 0.5 BER: 0.014777777777777779\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: 1.0 BER: 0.009822222222222222\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 1.5 BER: 0.005533333333333334\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 2.0 BER: 0.0026222222222222224\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 2.5 BER: 0.0011111111111111111\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 3.0 BER: 0.0006222222222222223\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 3.5 BER: 0.0002666666666666667\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 4.0 BER: 0.00013333333333333334\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 4.5 BER: 2.2222222222222223e-05\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 5.0 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 5.5 BER: 0.0\n",
      "1407/1407 [==============================] - 7s 5ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 6.0 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 7s 5ms/step\n",
      "SNR: 6.5 BER: 0.0\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 7.0 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 7.5 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 8.0 BER: 0.0\n"
     ]
    }
   ],
   "source": [
    "EbNodB_range = list(frange(-4,8.5,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = encoded_signal + noise\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a6e157e3e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(7,4)')\n",
    "#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('AutoEncoder_7_4_BER_matplotlib')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, GaussianNoise\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 4 k: 2\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "M = 4\n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "print ('M:',M,'k:',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 10000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [0. 0. 0. 1.]\n",
      "2 [0. 0. 1. 0.]\n",
      "2 [0. 0. 1. 0.]\n",
      "2 [0. 0. 1. 0.]\n",
      "0 [1. 0. 0. 0.]\n",
      "0 [1. 0. 0. 0.]\n",
      "1 [0. 1. 0. 0.]\n",
      "3 [0. 0. 0. 1.]\n",
      "3 [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "R = 1\n",
    "n_channel = 2\n",
    "print (int(k/R))\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = BatchNormalization()(encoded1)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "#sgd = SGD(lr=0.001)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2)                8         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 2)                0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 66\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_val = 1500\n",
    "val_label = np.random.randint(M,size=N_val)\n",
    "val_data = []\n",
    "for i in val_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    val_data.append(temp)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 3s 20ms/step - loss: 1.5632 - val_loss: 1.4031\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 1.4040 - val_loss: 1.3443\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 1.2569 - val_loss: 1.2500\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1.1276 - val_loss: 1.1455\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 1.0152 - val_loss: 1.0352\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.9140 - val_loss: 0.9337\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.8160 - val_loss: 0.8311\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.7181 - val_loss: 0.7278\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.6240 - val_loss: 0.6264\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.5385 - val_loss: 0.5233\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4648 - val_loss: 0.4329\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3978 - val_loss: 0.3595\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3405 - val_loss: 0.2987\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2882 - val_loss: 0.2475\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2433 - val_loss: 0.2053\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2053 - val_loss: 0.1691\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1706 - val_loss: 0.1397\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1446 - val_loss: 0.1153\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1215 - val_loss: 0.0957\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1033 - val_loss: 0.0800\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0878 - val_loss: 0.0679\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0766 - val_loss: 0.0580\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.0499\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0584 - val_loss: 0.0431\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0514 - val_loss: 0.0377\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0454 - val_loss: 0.0332\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0294\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0262\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0324 - val_loss: 0.0234\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0211\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0269 - val_loss: 0.0191\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0173\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0158\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0144\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0096\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0089\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 9.9855e-04\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 9.6626e-04\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 9.2874e-04\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 8.9884e-04\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 8.5982e-04\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.3292e-04\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 8.1161e-04\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.8530e-04\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 7.5944e-04\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 7.3059e-04\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 7.0511e-04\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.8391e-04\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.5977e-04\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.4091e-04\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 6.1927e-04\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.9786e-04\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 5.7803e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b620fcb2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data, data,\n",
    "                epochs=100,\n",
    "                batch_size=300,\n",
    "                validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 45000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2\n"
     ]
    }
   ],
   "source": [
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2b620fc9960>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: -4 BER: 0.09013333333333333\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -3.5 BER: 0.07497777777777778\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: -3.0 BER: 0.05837777777777778\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -2.5 BER: 0.04817777777777778\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -2.0 BER: 0.034022222222222225\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: -1.5 BER: 0.024266666666666666\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: -1.0 BER: 0.018333333333333333\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -0.5 BER: 0.01331111111111111\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: 0.0 BER: 0.008311111111111111\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 0.5 BER: 0.006022222222222222\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: 1.0 BER: 0.003022222222222222\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 1.5 BER: 0.0016444444444444445\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 2.0 BER: 0.0011333333333333334\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: 2.5 BER: 0.0004888888888888889\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "SNR: 3.0 BER: 0.00017777777777777779\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 3.5 BER: 4.4444444444444447e-05\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 4.0 BER: 2.2222222222222223e-05\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 4.5 BER: 4.4444444444444447e-05\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 5.0 BER: 2.2222222222222223e-05\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 5.5 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 6.0 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 6.5 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 7.0 BER: 0.0\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: 7.5 BER: 0.0\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 8.0 BER: 0.0\n"
     ]
    }
   ],
   "source": [
    "EbNodB_range = list(frange(-4,8.5,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = encoded_signal + noise\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b62334abf0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgjklEQVR4nO3dfXRU9b3v8fdXxGLEg4rC8pSHxIoPGEAJPiC1EhUPXp9u1VpZKatVNKdWqu2tS22xV22l9d56PVahx4NPtDULatV2qbXVKg8qt56CKKBBPRyPaNBeHlQwRVDge//YkzgJyc6eyeyZPXs+r7VmJfs3++H7I8l82fv3ZO6OiIhId/YodQAiIpJsShQiIhJKiUJEREIpUYiISCglChERCbVnqQOIw4EHHujV1dV5Hfv3v/+dffbZp7ABlYjqkjxpqQeoLknU23q8+OKLG939oM7lqUwU1dXVLFu2LK9jFy1axMSJEwsbUImoLsmTlnqA6pJEva2Hma3tqlyPnkREJJQShYiIhFKiEBGRUIlvozCzQ4AZwAB3v6DU8Yik1aeffkpLSwvbtm2LtP+AAQNYvXp1zFEVR1rqErUe/fr1Y8iQIfTt2zfSeWNNFGZ2H3AWsN7da7PKJwM/B/oA97j7Ld2dw93fBKaZ2UNxxipS6VpaWth3332prq7GzHrc/6OPPmLfffctQmTxS0tdotTD3dm0aRMtLS3U1NREOm/cj57mApOzC8ysDzAbOAMYCUwxs5FmNsrMHu/0GhRzfO2amqC6Gk455WSqq4NtkUqybds2Bg4cGClJSPkyMwYOHBj5zhFivqNw92fNrLpT8XHAmsydAmY2HzjX3X9KcPeRFzNrBBoBBg8ezKJFiyIf+/TTg7j11sPZvr0PYKxdC9Om7WT16tc57bT1+YZUcq2trTn9OyRZWuqS5HoMGDCA1tbWyPvv3LmTjz76KMaIiictdcmlHtu2bYv+u+jusb6AauCVrO0LCB43tW1PBWaFHD8QuAv4T+D7Ua5ZV1fnuRg+3B12fw0fntNpEmfhwoWlDqFg0lKXJNejubk5p/23bNkSUyTFl5a65FKPrn7ewDLv4jM18Y3Z7r4J+GaUfc3sbODsQw89NKdrvP12buUiIpWkFN1j1wFDs7aHZMp6zd0fc/fGAQMG5HTcsGG5lYsIPPjgnlRXwx57UNB2vd///veYGa+99lqP+95+++1s3bq1MBcukLlz5zJ9+vScj3vppZeYNm0aAE1NTYwePZpRo0Zx4oknsmLFit3237p1K2eeeSZHHHEERx11FNddd137e7NmzeK+++7LvxKdlCJRLAVGmFmNme0FXAQ8WoI42s2cCVVVHcuqqoLyMG0N4IX+QxFJuqYm+Pa3+7F2bfCgdu1aaGwszN/AvHnz+OIXv8i8efN63DeJiSJXO3bsAOAnP/kJV155JQA1NTUsXryYVatW8cMf/pDGxsYuj7366qt57bXXeOmll1iyZAlPPfUUAJdccgl33nlnwWKMNVGY2TzgL8DhZtZiZtPcfQcwHXgSWA086O6vFuh6Z5vZnM2bN+d0XEMDzJkDw4eDmTN8eLDd0ND9MU1NwR9GHH8oIkk3YwZ8/HHH3lFbtwblvdHa2srzzz/Pvffey/z584Fg/qKzzvqsn8v06dOZO3cud9xxB++++y719fXU19cDQZIZNWoUtbW1XHvtte3HPPXUU4wfP56xY8fyla98pb3Rvrq6mhtuuIGTTjqJUaNGtd/FtLa2cvHFFzNq1ChGjx7Nww8/HHr++++/n8MOO4zjjjuOJUuWtJdv2LCB888/n2OPPZZjjz22/b0bb7yRqVOnMmHCBKZOncpHH33EypUrGTNmDAAnnngi+++/PwAnnHACLS0tu/1bVVVVtdd7r732YuzYsbz77rvt71VXV/PXv/41759FB101XJT7K9fG7GxRGxvLoQE8yQ2nuUpLXZJcj1was826/v03610MDzzwgF9yySXu7j5+/HhftmyZL1y40M8888z2fa644gq///773d19+PDhvmHDBnd3X7dunQ8dOtTXr1/vn376qdfX1/vvfvc737Bhg5900kne2trq7u633HKL33TTTe3H33HHHb5lyxafPXu2T5s2zd3dr7nmGr/qqqvar/n+++93e/533323vXz79u1+4okn+hVXXOHu7lOmTPHnnnvO3d3Xrl3rRxxxhLu733DDDT527FjfunWru7svWLDAzzvvvC7/TX72s5+1x9WdDz74wGtqanzFihXtZTfffLPfeuut3R6TqsbspFIDuFSyYcOCu+iuyntj3rx5XHXVVQBcdNFFzJs3r8PdRJilS5cyceJEDjoomCW7oaGBZ599lj333JPm5mYmTJgAwCeffML48ePbjzvvvPMAqKur45FHHgHg6aefbr+jAdh///159tlnuzw/0KH8q1/9Km+88Ub7eZqbm9vPs2XLlva7mXPOOYe9994bgPfee6/9+GwLFy7k3nvv5fnnn++23jt27GDKlClceeWVHQbQDRo0KFI7TxSpShT59nrKR1x/KCLlYOZMuOwy7/D4KUq7Xpj333+fBQsWsGrVKsyMnTt3Ymace+657Nq1q32/XAaKQfDUZNKkSd22eXzuc58DoE+fPu3tBYWya9cuXnjhBfr167fbe9nrRuy999671WvlypVceuml/PGPf2TgwIHdXqOxsZERI0bwne98p8MYim3btrUnot5K1aSAnmevp3zk2wAukgYNDXDnndsy7XpEatfryUMPPcTUqVNZu3Ytb731Fu+88w41NTXs2rWL5uZmtm/fzocffsgzzzzTfsy+++7b/uF43HHHsXjxYjZu3MjOnTuZN28eJ598MieccAJLlixhzZo1QLC4T9v/+LszadIkZs+e3b79wQcfdHv+448/nsWLF7Np0yY+/fRTfvvb37Yfd/rpp3doVH755Ze7vN6RRx7ZHh/A22+/zXnnncevf/1rDjvssA77nnrqqaxbF3QUvf7669m8eTO33377bud84403qK2t3a08H6lKFMXUsQE82h+KeklJmlx44Q7eegt27YK33updkoDgsdOXv/zlDmXnn38+8+fP58ILL6S2tpYLL7yQY445pv39xsZGJk+eTH19PQcffDC33HIL9fX1jBkzhrq6Os4991wOOugg5s6dy5QpUxg9ejTjx4/v8ZHM9ddfzwcffEBtbS1jxoxh4cKF3Z7/4IMP5sYbb2T8+PFMmDCBI488sv08d9xxB8uWLWP06NGMHDmSu+66q8vrHXHEEWzevLk96f3oRz9i06ZNfOtb3+Loo49m3LhxQHCHsmbNGg444ABaWlqYOXMmzc3NjB07lqOPPppf/vKX7edcsmQJkyZNyu2H0J2uGi7K/VWMxuxcPfCAe1VVx4a/qqqgPC5JbjjNVVrqkuR6aGR2ad12221+9913h+6zatUq/+53v9vt+231WL58uX/ta18LPVcujdmpuqPIt3tsMcyYEXQfzFaI7oQikg6XX355e3tJd2pra7ntttt6PNfGjRv58Y9/XKjQ0pUovIhtFLlSLykpB8F/KqUU+vXrx9SpUwtyrkmTJlFdXd3t+7n+nFOVKJIs32lC1K4hxdKvXz82bdqkZJFy7sF6FF31xOpOqrrHJtnMmcHI7ezHTz31kmob/d12TNvob+h9w6FIZ0OGDKGlpYUNGzZE2n/btm05fdgkWVrqErUebSvcRZWqRFHMcRS5avtgnzEjeNw0bFiQJMI+8MPaNZQopND69u0becUzCKbWyO6BVM7SUpe46pGqR09JbqOA4MM9l+6EatcQkSRIVaJIG01/LiJJoESRYBr9LSJJoESRYPmM/hYRKbRUNWanUUODEoOIlFaq7iiSPDK7mNrGXpxyyskaeyEivZaqRJH0Xk/F0HHlPdPKeyLSa6lKFKI5pUSk8JQoUkZjL0Sk0JQoUkZjL0Sk0JQoUkZjL0Sk0FKVKNTrqfPYC9fYCxHptVQlCvV6CrTNKbVgweKCLFEpIpUtVYlC8qd1L0SkOxqZLVr3QkRC6Y5CNPZCREIpUYjGXohIKCUK0dgLEQmlRCEaeyEioZQoROteiEgoJQoBcl/PW91pRSpHqrrHmtnZwNmHHnpoqUNJNXWnFaksqbqj0Mjs4lB3WpHKkqpEIcWh7rQilUWJQnKm7rQilUWJQnKm7rQilUWJQnKm7rQilSVVvZ6keBoalBhEKoXuKKRoNPZCpDzpjkKKQmMvRMqX7iikKDT2QqR8KVFIUWjshUj5UqKQotDYC5HypUQhRaGxFyLlqywShZn9dzO728x+Y2anlzoeyZ3GXoiUr9gThZndZ2brzeyVTuWTzex1M1tjZteFncPdf+/ulwHfBL4aZ7wSn1ynMheRZChG99i5wCzgV20FZtYHmA1MAlqApWb2KNAH+Gmn4y9x9/WZ76/PHCciIkUSe6Jw92fNrLpT8XHAGnd/E8DM5gPnuvtPgbM6n8PMDLgF+KO7L485ZBERyWLuHv9FgkTxuLvXZrYvACa7+6WZ7anA8e4+vZvjrwS+DiwFXnb3u7rYpxFoBBg8eHDd/Pnz84q1tbWV/v3753Vs0qguyZOWeoDqkkS9rUd9ff2L7j5utzfcPfYXUA28krV9AXBP1vZUYFahrldXV+f5WrhwYd7HJk0a6vLAA+7Dh7ub7fLhw4PtcpaGn0kb1SV5elsPYJl38Zlaqik81gFDs7aHZMp6RUuhpkvHaT9M036IlEipuscuBUaYWY2Z7QVcBDza25O6lkJNFU37IZIMxegeOw/4C3C4mbWY2TR33wFMB54EVgMPuvurccci5UXTfogkQzF6PU3ppvwJ4IlCXkuPntJl2LBgltmuykWkeMpiZHZUevSULpr2QyQZUpUoJF06TvvhmvZDpER6TBRmVmVmPzSzuzPbI8xst0FxSWBmZ5vZnM2bN5c6FCmQtmk/FixYrGk/REokyh3F/cB2YHxmex1wc2wR9YIePYmWWxUpvCiJ4gvu/r+BTwHcfStgsUYlkoe2cRdr14L7Z8utKlmI9E6URPGJme0NOICZfYHgDkMkUTTuQiQeURLFjcCfgKFm1gQ8A1wbZ1D5UhtFZdO4C5F49Jgo3P0p4DzgG8A8YJy7L4w5rryojaKyablVkXhE6fX0jLtvcvc/uPvj7r7RzJ4pRnAiudC4C5F4dJsozKyfmR0AHGhm+5vZAZlXNfD5okUoEpGWWxWJR9gUHv8MfAf4R+BFPuvptIVgxbrE0RQe0tCgxCBSaN3eUbj7z929Brja3Q9x95rMa4y7JzJRqI1CRKTwepwU0N3vNLNaYCTQL6v8V90fJSIiadFjojCzG4CJBIniCeAM4HlAiUJEpAJEGUdxAXAq8Dd3vxgYA+jZjohIhYiSKD52913ADjP7B2A9HZcxTQwNuBMRKbwoiWKZme0H3E3Q+2k5wYp1iaPGbBGRwovSmP2tzLd3mdmfgH9w95XxhiUiIkkRekdhZn3M7MCsoneBE8xsdbxhiYhIUoSNzL4IeB9YaWaLzex04E2CXk8a0iSpoTUsRMKFPXq6Hqhz9zVmNpagXeICd3+sOKGJxK9tDYu26cnb1rAAjfAWaRP26OkTd18D4O7Lgf9QkpC00RoWIj0Lu6MYZGb/I2t7v+xtd78tvrDyo7meJFdaw0KkZ2F3FHcD+2a9Om8njrrHSq60hoVIz7q9o3D3m4oZiEgpzJzZsY0CtIaFSGdRBtyJpJbWsBDpWY8D7kTSTmtYiITracDdHmZ2YbGCERGR5AlNFJnJAK8pUiwiIpJAUdoonjazq81saNa62QfEHpmIiCRClDaKr2a+XpFV5sAhhQ9HRESSJsrssTXFCERERJIpylKofYHLgS9lihYB/+bun8YYV140MltEpPCitFH8K1AH/CLzqsuUJY5GZouIFF6URHGsu3/d3RdkXhcDx8YdmEiSaWpyqSRRGrN3mtkX3P0/AczsEGBnvGGJJJemJpdKE+WO4mpgoZktMrPFwALge/GGJZJcmppcKk3oHYWZ9QHGACOAwzPFr7v79rgDE0kqTU0ulaankdk7gSnuvt3dV2ZeShJS0TQ1uVSaKI+elpjZLDM7yczGtr1ij0wkoWbODKYiz6apySXNojRmH535+qOsMgdOKXg0ImWgrcF6xozgcdOwYUGSUEO2pFWUNopH3f1fihSPSFnQ1ORSSSK1URQpFpHUaht3ccopJ2vchZSdKI+elpjZLOA3wN/bCt19eWxRiaRIx3EXpnEXUnbURiESs7BxF0oUUg6izB5bX4xAumNmRwJXAQcCz7h7IueZEumOxl1Iueu2jcLMbs/6/qpO782NcnIzu8/M1pvZK53KJ5vZ62a2xsyuCzuHu692928CFwITolxXJEk07kLKXVhj9peyvv96p/dGRzz/XGBydkGmJ9Vs4AxgJDDFzEaa2Sgze7zTa1DmmHOAPwBPRLyuSGJo3IWUO3P3rt8we8ndj+n8fWZ7ubtHGnRnZtXA4+5em9keD9zo7v+U2f4+gLv/NMK5/uDuZ3bzXiPQCDB48OC6+fPnRwlvN62trfTv3z+vY5NGdUmOp58exD33HML69Z9j0KDtXHrpm5x22vpSh9Ur5f4zyZaWuvS2HvX19S+6+7jd3nD3Ll/ACmB/YGDW9wdkXiu6O66L81QDr2RtXwDck7U9FZgVcvxE4A7g34Arolyzrq7O87Vw4cK8j00a1SV50lIPd9UliXpbD2CZd/GZGtaYPQB4EbDMdnZ32K5vQ2Lg7osIVtUTEZES6DZRuHt1TNdcBwzN2h6SKes1LYUqIlJ4USYFLLSlwAgzqzGzvYCLgEcLcWLXUqgiIgUXa6Iws3nAX4DDzazFzKa5+w5gOvAksBp40N1fjTMOERHJX5SR2Xlz9y7niXL3J4ihq6sePYmIFF6PdxRmNq2LslviCad39OhJRKTwotxRnG9m29y9CcDMZgP94g1LRESSIlKiAB41s10Eo6w/dPfd7jKSQI+eREQKL2yupwPM7ABgb+BS4BrgI+CmTHni6NGTiEjhhd1RvEgwsM6yvp6ZeTlwSOzRiYhIyYUNuKspZiCFoEdPIiKFF6XX0xVmtl/W9v5m9q1Yo8qTHj2JiBRelAF3l7n7h20b7v4BcFlsEYkI8Nk623vsgdbZlpKK0uupj5lZZmbBtvUk9oo3LJHK1nGdbbTOtpRUlDuKPwG/MbNTzexUYF6mTERiErbOtkixRbmjuBb4Z+DyzPafgXtii6gX1JgtaaF1tiVJekwU7r7LzO4FnifoFvu6u++MPbI8uPtjwGPjxo1TG4qUtWHDgsdNXZWLFFuUXk8Tgf8AZgG/AN4wsy+FHSMivaN1tiVJojx6+j/A6e7+OoCZHUbQTlEXZ2AilaytwXrGjOBx07BhQZJQQ7aUQpRE0bctSQC4+xtm1jfGmESEICkoMUgSREkUy8zsHuCBzHYDsCy+kPKnxmwRkcKL0j32cqAZuDLzauazHlCJopHZIiKFF6XX03bgtsxLREQqTLeJwsxWEXSH7ZK7j44lIhERSZSwO4qzihaFiIgkVtg047sN9zGzA4FNbfM+iYhI+oWtcHeCmS0ys0fM7BgzewV4Bfh/Zja5eCGKiEgphT16mgX8ABgALADOcPcXzOwIEjoxoLrHiogUXlj32D3d/Sl3/y3wN3d/AcDdXytOaLlT91gRkcILSxS7sr7/uNN7aqMQEakQYY+expjZFsCAvTPfk9nuF3tkIiKSCGG9nvoUMxAREUmmKFN4iIhIBVOiEBGRUEoUIiISSolCRERCKVGIpEhTE1RXwx57BF+bmkodkaRBlIWLyoZGZksla2qCxkbYujXYXrs22AatlCe9k6o7Co3Mlko2Y8ZnSaLN1q1BuUhvpCpRiFSyt9/OrVwkKiUKkZQYNiy3cpGolChEUmLmTKiq6lhWVRWUi/SGEoVISjQ0wJw5MHw4mAVf58xRQ7b0Xqp6PYlUuoYGJQYpPN1RiIhIKCUKEREJpUQhIiKhlChERCSUEoWIiIRSohARkVBlkSjMbB8zW2ZmZ5U6FhGRShNrojCz+8xsvZm90ql8spm9bmZrzOy6CKe6FngwnihFRCRM3APu5gKzgF+1FZhZH2A2MAloAZaa2aNAH+CnnY6/BBgDNAP9Yo5VRES6YO4e7wXMqoHH3b02sz0euNHd/ymz/X0Ad++cJNqOnwnsA4wEPga+7O67utivEWgEGDx4cN38+fPzire1tZX+/fvndWzSqC7Jk5Z6gOqSRL2tR319/YvuPq5zeSmm8Pg88E7WdgtwfHc7u/sMADP7BrCxqySR2W8OMAdg3LhxPnHixLyCW7RoEfkemzSqS/KkpR6guiRRXPUom7me3H1uqWMQEalEpej1tA4YmrU9JFPWa2Z2tpnN2bx5cyFOJyIilCZRLAVGmFmNme0FXAQ8WogTaylUEZHCi7t77DzgL8DhZtZiZtPcfQcwHXgSWA086O6vFuh6uqMQESmwWNso3H1KN+VPAE/EcL3HgMfGjRt3WaHPLSJSqcpiZLaIiJSOEoWIiIRKVaJQG4WISOGlKlGo15OISOGlKlGIiEjhpSpR6NGTiEjhpSpR6NGTiEjhpSpRiIhI4SlRiIhIKCUKkQrW1ATV1bDHHsHXpqbyvo7Eo2ymGY/CzM4Gzj700ENLHYpI4jU1QWMjbN0abK9dG2wDNDSU33UkPqm6o1Bjtkh0M2Z89uHdZuvWoLwcryPxSVWiEJHo3n47t/KkX0fio0QhUqGGDcutPOnXkfgoUYhUqJkzoaqqY1lVVVBejteR+KQqUWhktkh0DQ0wZw4MHw5mwdc5cwrfwFys60h8UtXrSQsXieSmoaE4H9jFuo7EI1V3FCIiUnhKFCIiEkqJQkREQilRiIhIKCUKEREJlapEoe6xIiKFl6pEobmeREQKL1WJQkRECk+JQkREQilRiEhO2hYhOuWUk2NbhEgLHSVLqqbwEJF4dVyEyGJZhEgLHSWP7ihEJLJiLEKkhY6SR4lCRCIrxiJEWugoeZQoRCSyYixCpIWOkidViUID7kTiVYxFiLTQUfKkKlFowJ1IvDouQuSxLEKkhY6SR72eRCQnbYsQLVq0mIkTJ8Z6DUmGVN1RiIhI4SlRiIhIKCUKEREJpUQhIiKhlChERCSUuXupYyg4M9sArM3z8AOBjQUMp5RUl+RJSz1AdUmi3tZjuLsf1LkwlYmiN8xsmbuPK3UchaC6JE9a6gGqSxLFVQ89ehIRkVBKFCIiEkqJYndzSh1AAakuyZOWeoDqkkSx1ENtFCIiEkp3FCIiEkqJQkREQilRhDCz75mZm9mBpY4lX2b2MzN7zcxWmtnvzGy/UseUCzObbGavm9kaM7uu1PHky8yGmtlCM2s2s1fN7KpSx9QbZtbHzF4ys8dLHUtvmNl+ZvZQ5m9ktZmNL3VM+TKz72Z+t14xs3lm1q9Q51ai6IaZDQVOB8p9AcY/A7XuPhp4A/h+ieOJzMz6ALOBM4CRwBQzG1naqPK2A/ieu48ETgCuKOO6AFwFrC51EAXwc+BP7n4EMIYyrZOZfR64Ehjn7rVAH+CiQp1fiaJ7/wJcA5R1a7+7P+XuOzKbLwBDShlPjo4D1rj7m+7+CTAfOLfEMeXF3d9z9+WZ7z8i+ED6fGmjyo+ZDQHOBO4pdSy9YWYDgC8B9wK4+yfu/mFJg+qdPYG9zWxPoAp4t1AnVqLogpmdC6xz9xWljqXALgH+WOogcvB54J2s7RbK9MM1m5lVA8cA/17iUPJ1O8F/onaVOI7eqgE2APdnHqPdY2b7lDqofLj7OuBWgicg7wGb3f2pQp2/YhOFmT2deZbX+XUu8APgf5Y6xqh6qEvbPjMIHn80lS5SMbP+wMPAd9x9S6njyZWZnQWsd/cXSx1LAewJjAX+1d2PAf4OlGU7mJntT3C3XQP8I7CPmX2tUOev2KVQ3f20rsrNbBTBP/YKM4PgUc1yMzvO3f9WxBAj664ubczsG8BZwKleXgNn1gFDs7aHZMrKkpn1JUgSTe7+SKnjydME4Bwz+29AP+AfzOwBdy/Yh1IRtQAt7t52Z/cQZZoogNOA/3L3DQBm9ghwIvBAIU5esXcU3XH3Ve4+yN2r3b2a4JdpbFKTRE/MbDLBY4Jz3H1rqePJ0VJghJnVmNleBI1zj5Y4prxY8L+Oe4HV7n5bqePJl7t/392HZP42LgIWlGmSIPM3/Y6ZHZ4pOhVoLmFIvfE2cIKZVWV+106lgA3zFXtHUUFmAZ8D/py5Q3rB3b9Z2pCicfcdZjYdeJKgF8d97v5qicPK1wRgKrDKzF7OlP3A3Z8oXUgCfBtoyvxH5E3g4hLHkxd3/3czewhYTvCI+SUKOJ2HpvAQEZFQevQkIiKhlChERCSUEoWIiIRSohARkVBKFCIiEkqJQoRg5Hpm5s2VZvaymR2fKV9kZsuy9htnZosy3080s82Z/V8zs1u7OXek/USSSolCKl5maumzCAZWjiYY5Zo9x9QgMzujm8Ofc/ejCeZuOsvMJvRyP5HEUaIQgYOBje6+HcDdN7p79sybPwNmhJ3A3T8GXqaHSQs772dml5nZUjNbYWYPm1lVpnyumd1hZv/XzN40swsy5XuY2S8ydyZ/NrMnst6rM7PFZvaimT1pZgfn8W8hshslChF4ChhqZm9kPoRP7vT+X4BPzKy+uxNkJmUbATwbdqEu9nvE3Y9197a1EKZl7X4w8EWCu51bMmXnAdUE63NMBcZnztsXuBO4wN3rgPuAmWGxiESlRCEVz91bgTqgkWDa6d9kJlLMdjNwfReHn2RmKwgmK3wyZE6w7varNbPnzGwV0AAclXXM7919l7s3A4MzZV8Efpsp/xuwMFN+OFBLMFXLy5lYy2ntEUkwJQoRwN13uvsid78BmA6c3+n9BcDeBKvTZXsuczdwFDDNzI7u5hLd7TcXmO7uo4CbCGZkbbM963vroQoGvOruR2deo9z99B6OEYlEiUIqnpkdbmYjsoqOBtZ2sevNBDPx7sbd/4vg8dC1YdfqYr99gfcyj44aIoS7BDg/01YxGJiYKX8dOCjTMI+Z9TWzo7o5h0hOlChEoD/wSzNrNrOVBM//b+y8U2am1w0h57kL+FJmBbsw2fv9kGCluyXAaxFifZhg6vtmgrUGlhOsZvYJcAHwvzKPuF4mWI9ApNc0e6xImTGz/u7eamYDgb8CE8p1vRQpD1qPQqT8PG5m+wF7AT9WkpC46Y5CRERCqY1CRERCKVGIiEgoJQoREQmlRCEiIqGUKEREJNT/BygZ5I+EOoocAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(2,2)')\n",
    "#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('AutoEncoder_2_2_BER_matplotlib')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, GaussianNoise\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 256 k: 8\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "M = 256\n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "print ('M:',M,'k:',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 10000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 256)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "13 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "67 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "163 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "79 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "139 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "244 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "129 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "173 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "R = 1\n",
    "n_channel = 8\n",
    "print (int(k/R))\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = BatchNormalization()(encoded1)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "#sgd = SGD(lr=0.001)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8)                32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNoi  (None, 8)                0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               2304      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,976\n",
      "Trainable params: 135,960\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_val = 1500\n",
    "val_label = np.random.randint(M,size=N_val)\n",
    "val_data = []\n",
    "for i in val_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    val_data.append(temp)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 4s 36ms/step - loss: 5.0229 - val_loss: 5.3685\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 3.7609 - val_loss: 4.7482\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 2.2968 - val_loss: 3.6487\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 1.1700 - val_loss: 2.3839\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.5590 - val_loss: 1.3380\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.2941 - val_loss: 0.6751\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.1744 - val_loss: 0.3189\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.1176 - val_loss: 0.1539\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0794\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.0664 - val_loss: 0.0428\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.0506 - val_loss: 0.0255\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0422 - val_loss: 0.0165\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.0356 - val_loss: 0.0115\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.0301 - val_loss: 0.0083\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.0256 - val_loss: 0.0064\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 1s 22ms/step - loss: 0.0220 - val_loss: 0.0050\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0202 - val_loss: 0.0041\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0179 - val_loss: 0.0035\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 0.0029\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.0025\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0126 - val_loss: 0.0022\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0115 - val_loss: 0.0019\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.0107 - val_loss: 0.0017\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0096 - val_loss: 0.0015\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 1s 14ms/step - loss: 0.0082 - val_loss: 0.0012\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0011\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 0.0010\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 9.0195e-04\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0065 - val_loss: 8.2241e-04\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0059 - val_loss: 7.5068e-04\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 6.9341e-04\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 6.4308e-04\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.0050 - val_loss: 6.0260e-04\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0049 - val_loss: 5.5865e-04\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 1s 21ms/step - loss: 0.0045 - val_loss: 5.1624e-04\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0043 - val_loss: 4.7271e-04\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 4.3985e-04\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 4.0421e-04\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0039 - val_loss: 3.8527e-04\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 3.5082e-04\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 3.2585e-04\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0029 - val_loss: 3.0179e-04\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.0028 - val_loss: 2.8063e-04\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 2.6285e-04\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 2.5014e-04\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 2.3410e-04\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 2.1920e-04\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 2.0919e-04\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0023 - val_loss: 1.9698e-04\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 1.8540e-04\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 1.7521e-04\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 1.7040e-04\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0020 - val_loss: 1.6039e-04\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 1.6432e-04\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0020 - val_loss: 1.5113e-04\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0018 - val_loss: 1.4176e-04\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 1.3496e-04\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0019 - val_loss: 1.3176e-04\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 1.3484e-04\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 1.2237e-04\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 1.1520e-04\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0018 - val_loss: 1.1311e-04\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 1.0489e-04\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 9.4075e-05\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 8.8388e-05\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0012 - val_loss: 8.3733e-05\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 8.2940e-05\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0012 - val_loss: 7.6539e-05\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0012 - val_loss: 7.1689e-05\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 7.0035e-05\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 6.6699e-05\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0011 - val_loss: 6.1890e-05\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0010 - val_loss: 5.7798e-05\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 5.6578e-05\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 9.2406e-04 - val_loss: 5.4956e-05\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 8.9364e-04 - val_loss: 5.1576e-05\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 8.7107e-04 - val_loss: 4.9139e-05\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 8.3336e-04 - val_loss: 4.6254e-05\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 8.3783e-04 - val_loss: 4.5146e-05\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 8.3154e-04 - val_loss: 4.3216e-05\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.4147e-04 - val_loss: 4.2148e-05\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 7.9890e-04 - val_loss: 4.1255e-05\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.5764e-04 - val_loss: 3.9787e-05\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 7.4474e-04 - val_loss: 3.8563e-05\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 7.6241e-04 - val_loss: 3.6606e-05\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 9.0069e-04 - val_loss: 4.1143e-05\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 8.3115e-04 - val_loss: 3.8277e-05\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 7.1521e-04 - val_loss: 3.4413e-05\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 7.7035e-04 - val_loss: 3.3080e-05\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.7913e-04 - val_loss: 3.2687e-05\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 8.2483e-04 - val_loss: 3.5042e-05\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 7.3039e-04 - val_loss: 2.9623e-05\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.4673e-04 - val_loss: 2.8807e-05\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 7.0612e-04 - val_loss: 2.8190e-05\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 6.6725e-04 - val_loss: 2.7349e-05\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 6.2551e-04 - val_loss: 2.5349e-05\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 5.5278e-04 - val_loss: 2.3820e-05\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 5.3099e-04 - val_loss: 2.2245e-05\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 5.7970e-04 - val_loss: 2.1097e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251912f7a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data, data,\n",
    "                epochs=100,\n",
    "                batch_size=300,\n",
    "                validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 45000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 162\n"
     ]
    }
   ],
   "source": [
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x251902278e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -4 BER: 0.49606666666666666\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 3ms/step\n",
      "SNR: -3.5 BER: 0.4393111111111111\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: -3.0 BER: 0.38324444444444444\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -2.5 BER: 0.32206666666666667\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -2.0 BER: 0.26586666666666664\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 6s 5ms/step\n",
      "SNR: -1.5 BER: 0.21586666666666668\n",
      "1407/1407 [==============================] - 7s 5ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -1.0 BER: 0.16613333333333333\n",
      "1407/1407 [==============================] - 8s 6ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: -0.5 BER: 0.12186666666666666\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 0.0 BER: 0.08864444444444444\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 0.5 BER: 0.06133333333333333\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 1.0 BER: 0.04142222222222222\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 1.5 BER: 0.0244\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 2.0 BER: 0.014666666666666666\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 2.5 BER: 0.00848888888888889\n",
      "1407/1407 [==============================] - 7s 5ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 3.0 BER: 0.0041333333333333335\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 3.5 BER: 0.0020666666666666667\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 4.0 BER: 0.0010222222222222223\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 4.5 BER: 0.00037777777777777777\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "SNR: 5.0 BER: 8.888888888888889e-05\n",
      "1407/1407 [==============================] - 6s 4ms/step\n",
      "1407/1407 [==============================] - 5s 4ms/step\n",
      "SNR: 5.5 BER: 8.888888888888889e-05\n",
      "1407/1407 [==============================] - 4s 3ms/step\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "SNR: 6.0 BER: 0.0\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "SNR: 6.5 BER: 0.0\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "SNR: 7.0 BER: 0.0\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "1407/1407 [==============================] - 2s 2ms/step\n",
      "SNR: 7.5 BER: 0.0\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "1407/1407 [==============================] - 3s 2ms/step\n",
      "SNR: 8.0 BER: 0.0\n"
     ]
    }
   ],
   "source": [
    "EbNodB_range = list(frange(-4,8.5,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = encoded_signal + noise\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x251953df010>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhSElEQVR4nO3de5RU5bnn8e8joNBA8IKgCZfGYFRsLtKIEmKkvYWMghNFA9NhJYhy4oHomfEsL8GMOhMS4znjnRwXopAsWBCjuYjxRENo0GjIAIqKKIYxtAJG8AqdVhT6mT+qqq1uunfvqq5dl12/z1q1uvdbe+96Xlr76f1ezd0RERFpzyGFDkBERIqbEoWIiARSohARkUBKFCIiEkiJQkREAnUtdABR6Nu3r1dWVmZ17T/+8Q969uyZ24AKRHUpPnGpB6guxaiz9diwYcM77n506/JYJorKykrWr1+f1bWrV69mwoQJuQ2oQFSX4hOXeoDqUow6Ww8zq2+rPFZNT2Y2ycwWfPjhh4UORUQkNmKVKNx9hbvP6tOnT6FDERGJjVglChERyb1Y9lGISHY+/fRTtm/fzscff9zhuX369OGVV17JQ1TRi0tdwtaje/fuDBgwgG7duoW6b6wShZlNAiYNHTq00KGIlKTt27fTu3dvKisrMbPAc/fu3Uvv3r3zFFm04lKXMPVwd9599122b9/OkCFDQt03Vk1PnemjWLoUKivhrLPOpLIycSxSbj7++GOOOuqoDpOElC4z46ijjgr11JgSqyeKbC1dCrNmQWMjgFFfnzgGqK0tZGQi+ackEX+Z/oxj9USRrblzU0niM42NiXIRkXIXq0SR7TyKN97IrDwl1Vx1yCGouUpEYitWiSLbPopBgzIrh8+aq+rrwZ3m5iolCyknUf2x9Jvf/AYz49VXX+3w3DvvvJPG1k0CBbZ48WLmzJmT8XXPP/88M2fOBODDDz9k0qRJjBw5kpNPPplFixa1ec0dd9zBySefTFVVFTNmzGjue5g6dSp//etfs69EmlglimzNmwcVFS3LKioS5e1Rc5WUu4ce6hrZH0vLli3jK1/5CsuWLevw3GJMFJnav38/AD/60Y+46qqrAJg/fz7Dhg3jhRdeYPXq1VxzzTV88sknLa7bsWMHd999N+vXr2fTpk00NTWxfPlyAK688kpuu+22nMSnREGiw3rBAhg8GMycwYMTx0Ed2dk0V6mpSuLkllsOi+SPpYaGBv70pz/xwAMPNP/SW716NRdccEHzOXPmzGHx4sXcfffd7Ny5k5qaGmpqaoBEkhk+fDhVVVVcd911zdc8+eSTjBs3jtGjR3PJJZfQ0NAAJNaGmzdvHqNHj2b48OHNTzENDQ3MmDGD4cOHM2LECB555JHA+y9atIgvfelLjB07lmeeeaa5fPfu3Vx88cWceuqpnHrqqc3v3XzzzUyfPp3x48czffp09u7dy4svvsjIkSOBRIfz3r17cXcaGho48sgj6dr14PFH+/fv56OPPmL//v00Njby+c9/HoAzzjiDlStXNiehTnH32L2qq6s9W3V1daHOGzzYPfF3VMvX4MFtn79kiXtFRctzKyoS5VEJW5dSEJe6FHs9Nm/eHPpcs6Y2/x8w61wMS5Ys8csuu8zd3ceNG+fr16/3uro6P//885vPmT17ti9atMjd3QcPHuy7d+92d/cdO3b4wIEDfdeuXf7pp596TU2N//rXv/bdu3f7GWec4Q0NDe7ufuutt/ott9zSfP1tt93m7u7z58/3mTNnurv7tdde61dffXXzZ7733nvt3n/nzp3N5fv27fMvf/nLPnv2bHd3nzZtmj/99NPu7l5fX+8nnniiu7vfdNNNPnr0aG9sbHR391WrVvlFF13U/Hl79uzxCRMm+DHHHOM9e/b0xx57rM1/rzvvvNN79uzpffv29UsuuaTFe+ecc46vX7++zeva+lkD672N36mxeqLI56KAmTZXqalK4mbAAG+zPKhvL4xly5YxdepUINHOHqb5KWXdunVMmDCBo48+mq5du1JbW8tTTz3F2rVr2bx5M+PHj2fUqFH87Gc/o77+s4VSJ0+eDEB1dTXbtm0DYOXKlcyePbv5nCOOOKLd+//lL39pLj/00EP55je/2XzdypUrmTNnDqNGjWLy5Mns2bOn+Wlm8uTJ9OjRA4C33nqLo4/+bIXvJ554glGjRrFz5042btzInDlz2LNnT4v6vv/++/z2t7/lb3/7Gzt37qSxsZElS5Y0v9+vXz927twZ+t+vPbGaR+HuK4AVY8aMuSLqz0o1S82dm2huGjQokSTaa67KdmSVSLG66aZ9XHVVjxZ/AHXUt9eR9957j1WrVvHSSy9hZhw4cAAz48ILL6Spqan5vEwmi0Gi5eTcc89tN+kcdthhAHTp0iU3TTVpmpqaWLt2Ld27dz/ovfS9I3r06NGiXosWLeL666/HzBg6dChDhgzh1VdfZezYsc3nrFy5kiFDhjQnmEmTJvHss8/yrW99C0j8O6USUWfE6oki32prYds2aGpKfA3q08hmZBWoX0OK16WX7k/r2yNU315HHn74YaZPn059fT3btm3jzTffZMiQITQ1NbF582b27dvHBx98wB//+Mfma3r37s3evXsBGDt2LGvWrOGdd97hwIEDLFu2jDPPPJPTTz+dZ555hq1btwKJDX5ee+21wFjOPfdc5s+f33z8/vvvt3v/0047jTVr1vDuu+/y6aef8stf/rL5uvPOO4977rmn+Xjjxo1tft5JJ53UHB/AoEGDmuv59ttvs2XLFo477jgATjzxxOZz1q5dS2NjI+7OmjVrOOmkk5rv8dprr1FVVRVYzzCUKPIkm5FVGoIrxS6TP5bCWLZsGd/4xjdalF188cUsX76cSy+9lKqqKi699FJOOeWU5vdnzZrFxIkTqamp4dhjj+XWW2+lpqaGkSNHUl1dzYUXXsjRRx/N4sWLmTZtGiNGjGDcuHEdDr298cYbef/996mqqmLkyJHU1dW1e/9jjz2Wm2++mXHjxjF+/PgWv6xTo5JGjBjBsGHDuO+++9r8vBNPPJEPP/ywOen94Ac/4Nlnn2X48OGcffbZ/OQnP6Fv37688847JLoT4LTTTmPKlCnNHfFNTU3MSi4r8fbbb9OjRw+OOeaYzH8QrbXVcVHqr3x0ZmdjyZJEZ7dZ4mtHHdmZdpi3Vuwdp5mIS12KvR6ZdGbv2bMnwkjyq1jqcvvtt/v9998feM6KFSv8rrvuavO99HrcfvvtvnDhwnbvk0lndqz6KIpdbW1mf3GpX0OkvFx55ZUtmq3akj5MOMjhhx/O9OnTcxGWmp6KWbb9GiKd4d72aCaJXvfu3XP2y33GjBltzruAzH/GsUoUcdszO5t+DdCS6ZK97t278+677ypZxJh7Yj+KtkZhtSdWTU+ex+Gx+ZDpEFzQkunSOQMGDGD79u3s3r27w3M//vjjjH7ZFLO41CVsPVI73IUVq0QRR5n2awRN7FOikI5069Yt9K5nq1evbjH6qJTFpS5R1SNWTU+iDnARyT0lipjRxD4RyTUlipjRxD4RyTUlipjJZsl0LVgoIkGUKGIotazCqlVrQi2roH4NEQmiRCGa2CcigWKVKOI24S5fsp3YJyLlIVaJwt1XuPusPn36FDqUktKyXyPcctEaJSVSPjThToDMJva1nP2NZn+LxFysnigkPzRKSqS8KFFIxjRKSqS8KFFIxjRKSqS8KFFIxjRKSqS8KFFIxrIZJSUipUuJQrKSmv3d1ESo2d+gIbUipUrDYyUvNKRWpHTpiULyQkNqRUqXEoXkhYbUipQuJQrJCw2pFSldRZ8ozOw4M3vAzB4udCySPQ2pFSldkSYKM3vQzHaZ2aZW5RPNbIuZbTWz64Pu4e6vu/vMKOOU6GlIrUjpinrU02LgXuDnqQIz6wLMB84FtgPrzOxRoAvw41bXX+buuyKOUfIkk4UHRaR4mLtH+wFmlcBj7l6VPB4H3OzuX0se3wDg7q2TROv7POzuUwLenwXMAujfv3/18uXLs4q3oaGBXr16ZXVtsYlDXVau7MfChcexa9dh9Ou3j8svf51zzindvx3i8DNJUV2KT2frUVNTs8Hdxxz0hrtH+gIqgU1px1OAhWnH04F7A64/CrgP+H/ADWE+s7q62rNVV1eX9bXFptTrsmSJe0WFO3z2qqhIlJeqUv+ZpFNdik9n6wGs9zZ+pxZ9Z7a7v+vu33X3L3rHTx3a4S5GNPdCpDgUIlHsAAamHQ9IlnWaa4e7WNHcC5HiUIhEsQ443syGmNmhwFTg0QLEIUVOcy9EikPUw2OXAX8GTjCz7WY20933A3OAJ4BXgIfc/eUcfZ6anmJEcy9EikOkw2PdfVo75Y8Dj0fweSuAFWPGjLki1/eW/EsNpZ07F954wxk0yJg3T0NsRfKt6DuzpbylljNftWpN6OXMRSS3YpUo1PQk2vNCJPdilSg06qm8pfa8qK9PzLpI7XmhZCHSObFKFFLeNO9CJBpKFBIbmnchEo1YJQr1UZQ3zbsQiUasEoX6KMqb5l2IRCNWiULKm/a8EIlG1PtRiOSV9rwQyb1YPVGoj0JEJPdilSjURyHZ0CQ9kWBqepKylpqkl5p/kZqkB2rCEkmJ1ROFSKY0SU+kY0oUUtY0SU+kY7FKFOrMlkxpkp5Ix2KVKNSZLZnSJD2RjsUqUYhkSpP0RDrW4agnM6sArgEGufsVZnY8cIK7PxZ5dCJ5oEl6IsHCPFEsAvYB45LHO4AfRhaRiIgUlTCJ4ovufhvwKYC7NwIWaVQiIlI0wiSKT8ysB+AAZvZFEk8YIiJSBsIkipuB3wMDzWwp8EfguiiDypaGx4qI5F6HicLdnwQuAr4DLAPGuHtdxHFlRcNjJV+0PpSUkzCjnv7o7mcDv2ujTKTsaH0oKTftPlGYWXczOxLoa2ZHmNmRyVcl8IW8RShSZLQ+lJSboCeKfwL+Bfg8sIHPRjrtAe6NNiyR4qX1oaTctJso3P0u4C4z+56735PHmESK2qBBieamtspF4qjDPgp3v8fMqoBhQPe08p9HGZhIsZo3r2UfBWh9KIm3Dkc9mdlNwD3JVw1wGzA54rhEipbWh5JyE2aHuynASOB5d59hZv2BJdGGJVLctD6UlJMwE+4+cvcmYL+ZfQ7YBQyMNqzsaMKdiEjuhUkU683scOB+EqOfngP+HGVQ2dKEOxGR3AvTmf3PyW/vM7PfA59z9xejDUtERIpF4BOFmXUxs75pRTuB083slWjDEhGRYhE0M3sq8B7wopmtMbPzgNeBrwPqxhPJQGptqLPOOlNrQ0nJCWp6uhGodvetZjaaRL/EFHdfkZ/QROKh5dpQprWhpOQENT194u5bAdz9OeCvShIimdPaUFLqgp4o+pnZ/0g7Pjz92N1vjy4skfjQ2lBS6oKeKO4Heqe9Wh+LSAjtrQGltaGkVAQtCnhLPgMRiSutDSWlLsyEOxHphJZrQ7nWhpKSo0Qhkge1tbBtG6xatYZt25QkpLR0NOHuEDO7NF/BBMTxX83sfjP7RXI+h4iI5ElgokguBnhtZz7AzB40s11mtqlV+UQz22JmW83s+g7i+I27XwF8F/hmZ+IREZHMhFlmfKWZ/SvwC+AfqUJ3fy/kZywmsXVq80ZHZtYFmA+cC2wH1pnZo0AX4Metrr/M3Xclv78xeZ2IiORJmESR+gt+dlqZA8eF+QB3f8rMKlsVjwW2uvvrAGa2HLjQ3X8MXND6HmZmwK3AfyYn/4mISJ6Yu0f/IYlE8Zi7VyWPpwAT3f3y5PF04DR3n9PO9VcB3wbWARvd/b42zpkFzALo379/9fLly7OKtaGhgV69emV1bbFRXYpPJvVYubIfCxcex65dh9Gv3z4uv/x1zjlnV8cX5klcfiYQn7p0th41NTUb3H3MQW+4e+AL6AZcBTycfM0BunV0Xat7VAKb0o6nAAvTjqcD92Zyz6BXdXW1Z6uuri7ra4uN6lJ8wtZjyRL3igp3+OxVUZEoLxZx+Zm4x6cuna0HsN7b+J0aZnjsfwDVwE+Tr+pkWWfsoOUueQOSZZ2iHe4kLrQ+lBSTMH0Up7r7yLTjVWb2Qic/dx1wvJkNIZEgpgL/rZP3xBOLFq4YM2bMFZ29l0ghaX0oKSZhnigOmNkXUwdmdhxwIOwHmNkyEkuUn2Bm281sprvvJ9GE9QTwCvCQu7+cWegi8aX1oaSYhHmi+FegzsxeBwwYDMwI+wHuPq2d8seBx8PeJwwzmwRMGjp0aC5vK5J3Wh9KikmHW6ECI4HjSXRofw84wd3r8hBbxtx9hbvP6tOnT6FDEemUlutDofWhpKACnyjc/YCZTXP3O4AX8xSTiJBICkoMUgzCND09Y2b3cvDM7KKb+KamJxGR3AuTKEYlv/6vtDIHzsp5NJ2kUU8iIrkXmCiSfRSPJpueRESkDHW0euwBoM1RS8VIE+5ERHIvzDyKZ8zsXjM7w8xGp16RR5YFjXoSEcm9WPVRiIhI7nWYKNy9Jh+BiIhIcWq36cnM7kz7/upW7y2OLiQRESkmQX0UX037/tut3hsRQSydps5sEZHcC0oU1s73RUud2VLuli6Fyko45JDE16VLCx2RxEFQH8UhZnYEiWSS+j6VMLpEHpmIZGTp0pYLCdbXJ45BS4FI5wQ9UfQBNgDrgc8BzyWPNwC9ow9NRDKhzY4kKu0+Ubh7ZR7jEJFO0mZHEpUwE+5KhjqzpZxpsyOJSqwShTqzpZzNm5fY3CidNjuSXIhVohApZ9rsSKLSYaIws5ltlN0aTTgi0hm1tbBtGzQ1Jb4qSUguhFnr6WIz+9jdlwKY2Xyge7RhiYhIsQiVKIBHzawJmAh84O4HPWWIiEg8Ba31dKSZHQn0AC4HrgX2Arcky4uORj2JiOReUB9FarLdBqAOOBw4P6286GjUk4hI7gVNuBuSz0BERKQ4hRn1NNvMDk87PsLM/jnSqEREpGiEmUdxhbt/kDpw9/eBKyKLSEREikqYRNHFzJqXGTezLsCh0YUkIiLFJEyi+D3wCzM728zOBpYly0SkxGn/CgkjzDyK64B/Aq5MHv8BWBhZRCKSF9q/QsLqMFG4e5OZPQD8CXBgi7sfiDwyEYlU0P4VShSSrsNEYWYTgJ8B20jscDfQzL7t7k9FGpmIREr7V0hYYfoo/g9wnruf6e5fBb4G3BFtWNnRzGyR8LR/hYQVJlF0c/ctqQN3fw3oFl1I2dPMbJHwtH+FhBUmUaw3s4VmNiH5up8iXcJDRMLT/hUSVphRT1cCs4GrksdPAz+NLCIRyZvaWiUG6ViYUU/7gNuTLxERKTPtJgoze4nEcNg2ufuISCISEZGiEvREcUHeohARkaIVtMx4fesyM+sLvOvu7T5piIhIvATtcHe6ma02s1+Z2SlmtgnYBLxtZhPzF6KIiBRSUNPTvcD3gT7AKuDr7r7WzE5ECwOKiJSNoHkUXd39SXf/JfB3d18L4O6v5ic0EREpBkGJoint+49avac+ChGRMhGUKEaa2R4z2wuMSH6fOh6ep/gws5PM7D4ze9jMruz4ChGJUmoPi7POOlN7WJSJdhOFu3dx98+5e29375r8PnUcaq0nM3vQzHYlO8LTyyea2RYz22pm1wfdw91fcffvApcC48N8rohEI7WHRX09uFvzHhZKFvEWZq2nzlgMtBghldxKdT7wdWAYMM3MhpnZcDN7rNWrX/KaycDvgMcjjldEAgTtYSHxZVFPiTCzSuAxd69KHo8Dbnb3ryWPbwBw9x+HuNfv3P38dt6bBcwC6N+/f/Xy5cuzirehoYFevXpldW2xUV2KT6nX46yzzsTdDio3c1atWlOAiHKj1H8uKZ2tR01NzQZ3H9O6PMyigLn2BeDNtOPtwGntnZzcOOki4DACnijcfQGwAGDMmDE+YcKErIJbvXo12V5bbFSX4lPq9Rg0KNHsdHC5lXS9Sv3nkhJVPQqRKDLi7quB1QUOQ0RI7FWRvs82aA+LchB1H0VbdgAD044HJMs6TTvciUSr5R4Wrj0sykQhEsU64HgzG2JmhwJTgUdzcWPtcCcSvdpa2LYNVq1aw7ZtShLlINJEYWbLgD8DJ5jZdjOb6e77gTnAE8ArwEPu/nKUcYiISPYi7aNw92ntlD9OBENdzWwSMGno0KG5vrWISNkqRNNTZNT0JCKSe7FKFCIiknuxShQa9SQiknuxShRqehIRyb1YJQoREcm9WCUKNT2JiORerBKFmp5ERHIvVolCRERyT4lCREQCxSpRqI9CRCT3YpUo1EchIpJ7sUoUIiKSe0oUIiISSIlCRCK3dClUVsIhhyS+Ll1a6IgkE0W/FWomtMy4SPFZurTl9qn19Ylj0KZHpSJWTxTqzBYpPnPnttxjGxLHc+cWJh7JXKwShYgUnzfeyKxcio8ShYhEatCgzMql+ChRiEik5s2DioqWZRUViXIpDUoUIhKp2lpYsAAGDwazxNcFC9SRXUpiNepJRIpTba0SQymL1ROF1noSEcm9WCUKDY8VEcm9WCUKERHJPSUKEREJpEQhIiKBlChERCSQEoWIiARSohARkUBKFCIiEihWiUIT7kREci9WiUIT7kREci9WiUJERHJPiUJERAIpUYiISCAlChERCaREISIigZQoREQkkBKFiIgEUqIQEZFAShQiIhJIiUJERAIpUYiISKCSSBRm1tPM1pvZBYWORUSk3ESaKMzsQTPbZWabWpVPNLMtZrbVzK4PcavrgIeiiVJERIJ0jfj+i4F7gZ+nCsysCzAfOBfYDqwzs0eBLsCPW11/GTAS2Ax0jzhWERFpg7l7tB9gVgk85u5VyeNxwM3u/rXk8Q0A7t46SaSunwf0BIYBHwHfcPemNs6bBcwC6N+/f/Xy5cuzirehoYFevXpldW2xUV2KT1zqAdHWZeXKfixceBy7dh1Gv377uPzy1znnnF05vyYlLj+XztajpqZmg7uPOegNd4/0BVQCm9KOpwAL046nA/eGuM93gAvCfGZ1dbVnq66uLutri43qUnziUg/36OqyZIl7RYU7fPaqqEiU5/KadHH5uXS2HsB6b+N3akl0ZgO4+2J3f6zQcYhItObOhcbGlmWNjYnyXF4j4RUiUewABqYdD0iWdZq2QhUpfW+8kVl5ttdIeIVIFOuA481siJkdCkwFHs3FjV1boYqUvEGDMivP9hoJL+rhscuAPwMnmNl2M5vp7vuBOcATwCvAQ+7+co4+T08UIiVu3jyoqGhZVlGRKM/lNRJepInC3ae5+7Hu3s3dB7j7A8nyx939S+7+RXfP2Y9STxQipa+2FhYsgMGDwSzxdcGCRHkur5Hwop5HISKSsdrazH/JZ3ONhFMyo57CUNOTiEjuxSpRqOlJRCT3YpUoREQk95QoREQkUKwShfooRERyL/JFAQvBzHYD9Vle3hd4J4fhFJLqUnziUg9QXYpRZ+sx2N2Pbl0Yy0TRGWa23ttaPbEEqS7FJy71ANWlGEVVj1g1PYmISO4pUYiISCAlioMtKHQAOaS6FJ+41ANUl2IUST3URyEiIoH0RCEiIoGUKEREJJASRQAzu8bM3Mz6FjqWbJnZv5nZq2b2opn92swOL3RMmTCziWa2xcy2mtn1hY4nW2Y20MzqzGyzmb1sZlcXOqbOMLMuZva8mZX09sRmdriZPZz8f+QVMxtX6JiyZWb/Pfnf1iYzW2Zm3XN1byWKdpjZQOA8oNQ3U/wDUOXuI4DXgBsKHE9oZtYFmA98HRgGTDOzYYWNKmv7gWvcfRhwOjC7hOsCcDWJjcdK3V3A7939RGAkJVonM/sCcBUwxt2rgC4kdg/NCSWK9t0BXAuUdG+/uz+Z3FUQYC2JPcpLxVhgq7u/7u6fAMuBCwscU1bc/S13fy75/V4Sv5C+UNiosmNmA4DzgYWFjqUzzKwP8FUgtaHaJ+7+QUGD6pyuQA8z6wpUADtzdWMlijaY2YXADnd/odCx5NhlwH8WOogMfAF4M+14OyX6yzWdmVUCpwB/KXAo2bqTxB9RTQWOo7OGALuBRclmtIVm1rPQQWXD3XcA/06iBeQt4EN3fzJX9y/bRGFmK5Ntea1fFwLfB/5noWMMq4O6pM6ZS6L5Y2nhIhUz6wU8AvyLu+8pdDyZMrMLgF3uvqHQseRAV2A08B/ufgrwD6Ak+8HM7AgST9tDgM8DPc3sW7m6f9luheru57RVbmbDSfxjv2BmkGiqec7Mxrr73/MYYmjt1SXFzL4DXACc7aU1cWYHMDDteECyrCSZWTcSSWKpu/+q0PFkaTww2cz+C9Ad+JyZLXH3nP1SyqPtwHZ3Tz3ZPUyJJgrgHOBv7r4bwMx+BXwZWJKLm5ftE0V73P0ld+/n7pXuXkniP6bRxZokOmJmE0k0E0x298ZCx5OhdcDxZjbEzA4l0Tn3aIFjyool/up4AHjF3W8vdDzZcvcb3H1A8v+NqcCqEk0SJP+fftPMTkgWnQ1sLmBInfEGcLqZVST/WzubHHbMl+0TRRm5FzgM+EPyCWmtu3+3sCGF4+77zWwO8ASJURwPuvvLBQ4rW+OB6cBLZrYxWfZ9d3+8cCEJ8D1gafIPkdeBGQWOJyvu/hczexh4jkQT8/PkcDkPLeEhIiKB1PQkIiKBlChERCSQEoWIiARSohARkUBKFCIiEkiJQoTEzPXkypsvmtlGMzstWb7azNannTfGzFYnv59gZh8mz3/VzP69nXuHOk+kWClRSNlLLi19AYmJlSNIzHJNX2Oqn5l9vZ3Ln3b3USTWbrrAzMZ38jyRoqNEIQLHAu+4+z4Ad3/H3dNX3vw3YG7QDdz9I2AjHSxa2Po8M7vCzNaZ2Qtm9oiZVSTLF5vZ3Wb2rJm9bmZTkuWHmNlPk08mfzCzx9PeqzazNWa2wcyeMLNjs/i3EDmIEoUIPAkMNLPXkr+Ez2z1/p+BT8yspr0bJBdlOx54KuiD2jjvV+5+qrun9kKYmXb6scBXSDzt3JosuwioJLE/x3RgXPK+3YB7gCnuXg08CMwLikUkLCUKKXvu3gBUA7NILDv9i+RCiul+CNzYxuVnmNkLJBYrfCJgTbD2zqsys6fN7CWgFjg57ZrfuHuTu28G+ifLvgL8Mln+d6AuWX4CUEViqZaNyVhLae8RKWJKFCKAux9w99XufhMwB7i41furgB4kdqdL93TyaeBkYKaZjWrnI9o7bzEwx92HA7eQWJE1ZV/a99ZBFQx42d1HJV/D3f28Dq4RCUWJQsqemZ1gZsenFY0C6ts49YckVuI9iLv/jUTz0HVBn9XGeb2Bt5JNR7Uhwn0GuDjZV9EfmJAs3wIcneyYx8y6mdnJ7dxDJCNKFCLQC/iZmW02sxdJtP/f3Pqk5EqvuwPucx/w1eQOdkHSz/sBiZ3ungFeDRHrIySWvt9MYq+B50jsZvYJMAX4SbKJayOJ/QhEOk2rx4qUGDPr5e4NZnYU8H+B8aW6X4qUBu1HIVJ6HjOzw4FDgf+tJCFR0xOFiIgEUh+FiIgEUqIQEZFAShQiIhJIiUJERAIpUYiISKD/D+d6LUrVN2HbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(8,8)')\n",
    "#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('AutoEncoder_8_8_BER_matplotlib')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
